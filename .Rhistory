I have done some prep, though:
* removed trackloss
* converted GazeX and Y columns to AOI 1 or 0 columns
* merged in Subject information
# Analysis 1: By-subjects and By-items ANOVAs (i.e., F1 and F2)
Pros:
* simple
* allows for generalization beyond samples participants and sampled items.
Cons:
* lose all timing information
* what do we do with ambiguities between analyses?
We need to aggregate across trials by target within participants:
```{r}
agg_subjects <- data %>%
group_by(ParticipantName,Sex,Age,Target) %>%
summarise(PropAnimal = mean(Animate)) %>%
ungroup()
```
Visualize our aggregated data:
```{r}
ggplot(agg_subjects, aes(x=Target, y=PropAnimal)) +
geom_point(position=position_jitter(.3))
```
Use our best practices from the `lm()` tutorial to prepare and model these data:
```{r}
agg_subjects$TargetCoded <- ifelse(agg_subjects$Target == 'Artefact', -.5, .5)
```
There's no need to center here because these data are balanced (every subject is present in both conditions). But this is how we would center, anyways:
```{r}
agg_subjects$TargetCoded <- scale(agg_subjects$TargetCoded, center=T, scale=F)
```
Here we use `aov()` because it allows for a repeated-measures Error() term.
As we learned before, aov() uses Type I sums of squares, but with only one factor (i.e., no correlation issues), it's safe.
```{r}
model <- aov(PropAnimal ~ TargetCoded + Error(ParticipantName/TargetCoded), data = agg_subjects)
summary(model)
```
Looks good! That's our F2 "subjects" ANOVA.
Now we can do an F1 "items" ANOVA as well. This just involves slightly changing our `group_by()` call:
```{r}
agg_items <- data %>%
group_by(Trial,Target) %>%
summarise(PropAnimal = mean(Animate)) %>%
ungroup()
agg_items$TargetCoded <- ifelse(agg_items$Target == 'Artefact', -.5, .5)
```
Visualize effects by items:
```{r}
ggplot(agg_items, aes(x=Target, y=PropAnimal, fill=Trial)) +
geom_point(position=position_jitter(.3))
```
Normally, in an F2 analysis, we would include an Error() term because we would have observed each condition within each item and thus have a sense about the size of the condition effect for each item. However, this was a study with infants and we couldn't do that. So we won't include an Error() term here, and just do a between-subjects one-way ANOVA.
```{r}
model <- aov(PropAnimal ~ TargetCoded, data = agg_items)
summary(model)
```
These F1/F2 analyses are both crystal clear (reject the null!). But, in other cases, there can be ambiguit. For example, what if one is significant and the other is marginal?
Ideally, we could have one test which allows us to control for random trial AND subject factors simultaneously. Enter `lmer()`...
# Analysis 2: Simultaneous Trial and Subject Random Effects
Aggregate data by Trials (Items) and Participants (i.e., one datapoint for each trial).
```{r}
agg_sub_items <- data %>%
group_by(ParticipantName,Trial,Target) %>%
summarise(PropAnimal = mean(Animate)) %>%
ungroup()
agg_sub_items$TargetCoded <- ifelse(agg_sub_items$Target == 'Artefact', -.5, .5)
```
Fit a mixed-effects model allowing the intercept (represented by a "1") to vary by both Participants and Trials. By allowing the intercept to vary by subjects and items, we are allowing the model to estimate (and thus control for) each participants' and trials' mean tendency to look (cause participants to) look at the animal regardless of condition. For example, Billy may just love animals while Sammy may hate animals. Importantly, we want to know whether they word they heard (represented here by TargetCoded) caused them to look more/less to the animal above and beyond these baseline preferences.
```{r}
model <- lmer(PropAnimal ~ TargetCoded + (1 | ParticipantName) + (1 | Trial), data = agg_sub_items)
summary(model)
```
This looks good, and converges with our previous estimate of a significant effect.
Note that, at the top of the summary output, we can see that there is very little variance in our random effect estimates. This means that the model is having trouble estimating them and is therefore keeping them all very near zero.
This is likely the result of (a) small random differences between subjects and trials in this sample and, (b) a relatively small dataset. We will want to continue keep an eye on the variance of random effects -- when this is essentially 0, we may want to consider using a regular ANOVA.
But in the meantime let's dive into this model a bit more.
We can see the fixed effects:
```{r}
fixef(model)
```
Here, because we centered the variable, `Intercept` is the overall mean looking to animal. `TargetCoded` represents the difference between looking to the animal between our two conditions. If we subtract 1/2 of it from the intercept, we get our mean looking to the animal when the "Artefact" was named and, if we add 1/2 of it to the intercept, we get our mean looking to the animal when the "Animal" was named.
We can also see random effects (some people use these to describe individual differences):
```{r}
ranef(model)
```
Here they are nearly zero, which corresponds to our assessment of their variance earlier.
We can also see what the model's predictions were, for each participant/item. Here we will get the mean prediction for each subject for each type of Target trial.
```{r}
agg_sub_items$prediction <- predict(model, agg_sub_items)
ggplot(agg_sub_items, aes(x=Target, y=prediction, color=ParticipantName)) +
stat_summary(fun.y='mean', geom='point', position=position_jitter(.3))
```
You can see that the model is making different predictions for each subject. By allowing their intercepts to vary, the model is accounting for the fact that some kids just like looking at animals more than others. But it's being very conservative with its estimates because, frankly, we haven't given it much data to go on.
Importantly, with these models, we aren't limited to varying just the intercept by specific grouping factors. We can also vary slopes (i.e., fixed effects) by participants as well. By adding "TargetCoded" as a random slope, we allow the model to vary the magnitude of the difference between Target conditions within participants.
```{r}
model <- lmer(PropAnimal ~ TargetCoded + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items)
summary(model)
```
We now see an additional random effect by the `ParticipantName` group: `TargetCoded`. We also see that it is actually varying between subjects, suggesting the model is become more confident in the differences between our subjects.
Look at which participants responded stronger/weaker to the Target manipulation.
These random effects are centered with respect to the fixed effect estimated. Therefore, negative effects represented a weaker effect of TargetCoded for this participant. This could be a cool way to look at individual differences -- who is responding most accurately to the words spoken?
```{r}
ranef(model)
subject_slopes <- ranef(model)$ParticipantName
subject_slopes$subject <- factor(rownames(subject_slopes))
colnames(subject_slopes) <- c('Baseline','ConditionEffect','Subject')
ggplot(subject_slopes, aes(x=Subject, y=ConditionEffect)) +
geom_point() +
geom_text(aes(label=Subject),hjust=0,vjust=0,size=3) +
geom_hline(yint=0, linetype="dashed", alpha=.5) +
theme(axis.text.x=element_blank())
```
With this random slope included in the model, we see more variation now in our predictions by subjects. It's even picking up on the fact that participants consistently look to the animal and the real variance lies in whether they look away from the animal when the artefact is named.
```{r}
agg_sub_items$prediction <- predict(model, agg_sub_items)
ggplot(agg_sub_items, aes(x=Target, y=prediction, color=ParticipantName)) +
stat_summary(fun.y='mean', geom='point', position=position_jitter(.3))
```
# Two important questions:
Although you've just played around with your first two mixed-effects models, you're likely already asking yourself two pressing questions...
## Question 1: Which random effect structure should we specify?
If you are going to use mixed-effects models, you are going to require AT LEAST a random intercept for every natural "grouping" of data. However, beyond random intercepts, what random slopes should you include?
### Guidelines
One way you can decide this is by adhering to guidelines. Unfortunately, you'll find guidelines pull you in opposing directions.
For example, one school of thought (see Barr et al., 2013) is to "keep it maximal". That is, include every random effect that your experimental design permits (i.e., every factor that appeared across subjects or trials). Another school of thought (see Bates et al., 2015) is to keep it parsimonious. Don't overcomplexify your models with lots of random slopes, as this will make model estimates increasingly hard to reconcile with the data and risk overparamterizing your model:
```{r}
# commented out because it kills knitr
# model <- lmer(PropAnimal ~ TargetCoded + (1 + TargetCoded + Trial | ParticipantName) + (1 | Trial), data = agg_sub_items)
```
### Model comparison
A second way to decide is to think bottom-up from the data. Compare two models -- one with your random slope and another without your random slope -- and see if your random slope model is actually a better fit.
```{r}
model <- lmer(PropAnimal ~ TargetCoded + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items)
model_null <- lmer(PropAnimal ~ TargetCoded + (1 | ParticipantName) + (1 | Trial), data = agg_sub_items)
anova(model,model_null) # -2 log-likelihood ratio test, gives you Chisq(df) = X and a p-value.
```
We'll talk more about model comparison -- a very powerful tool -- in just a minute.
summary(model)
summary(model)
summary(model)
model <- lmer(PropAnimal ~ TargetCoded + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items)
model_null <- lmer(PropAnimal ~ 1 + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items)
anova(model,model_null)
log_model <- logLik(model)
log_model
log_null <- logLik(model_null)
log_null
exp(39)
log_model
log_null
View(agg_sub_items)
agg_sub_items$RandomFactor <- ifelse(rbinom(nrow(agg_sub_items),.5) == 1, 'On','Off')
?rbinom
agg_sub_items$RandomFactor <- ifelse(rbinom(nrow(agg_sub_items),1,.5) == 1, 'On','Off')
View(agg_sub_items)
model1 <- lmer(PropAnimal ~ TargetCoded + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items, REML=F)
model2 <- lmer(PropAnimal ~ RandomFactor + (1 + TargetCoded | ParticipantName) + (1 | Trial), data = agg_sub_items, REML=F)
anova(model1,model2)
library(ggplot2)
library(lme4)
library(dplyr)
data <- read.csv('data-eyetracking.csv')
binned <- data %>%
mutate(TimeFromSubphaseOnset = (TimeFromSubphaseOnset / 1000) %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
ungroup() %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) # arcsin-sqrt
binned <- data %>%
mutate(Bin = (TimeFromSubphaseOnset / 1000) %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
ungroup() %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) # arcsin-sqrt
binned <- data %>%
mutate(TimeS = TimeFromSubphaseOnset / 1000,
Bin = TimeFromSubphaseOnset %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
ungroup() %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) # arcsin-sqrt
View(binned)
binned <- data %>%
mutate(TimeS = TimeFromSubphaseOnset / 1000,
Bin = TimeFromSubphaseOnset %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
#ungroup() %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) # arcsin-sqrt
View(binned)
binned$TargetC <- ifelse(binned$Target == 'Animal', .5, -.5)
binned$TargetC <- scale(binned$TargetC, center=T, scale=F)
model <- lmer(elog ~ TargetC*TimeS + (1 + TargetC + TimeS | ParticipantName), data = binned)
summary(model)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line")
binned <- binned %>%
mutate(TimeS_2 = TimeS^2,
TimeS_3 = TimeS^3,
TimeS_4 = TimeS^4)
head(binned)
plot(binned$TimeS, binned$TimeS_2)
plot(binned$TimeS, binned$TimeS_3)
plot(binned$TimeS, binned$TimeS_4)
ggplot(binned, aes(x=TimeS, y=TimeS_2)) +
geom_point() +
geom_point(aes(y=TimeS_3)) +
geom_point(aes(y=TimeS_4))
ggplot(binned, aes(x=TimeS, y=TimeS)) +
geom_point() +
geom_point(aes(y=TimeS_2), color='red') +
geom_point(aes(y=TimeS_3), color='blue') +
geom_point(aes(y=TimeS_4), color='green')
model <- lmer(elog ~ Target*(TimeS + TimeS_2 + TimeS_3 + TimeS_4) + (1 + Target + TimeS + TimeS_2 + TimeS_3 + TimeS_4 | ParticipantName), data = binned)
summary(model)
ggplot(binned, aes(x=TimeS, y=elog)) +
stat_summary(fun.y='mean', geom='line')
ggplot(binned, aes(x=TimeS, y=elog)) +
stat_smooth(method="loess")
model <- lmer(elog ~ Target*(TimeS + TimeS_2 + TimeS_3) + (1 + Target + TimeS + TimeS_2 + TimeS_3 | ParticipantName), data = binned)
summary(model)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line")
natural_model <- model
cor(binned[, c('TimeS','TimeS_2','TimeS_3','TimeS_4')])
orthogonal_polynomials <- poly(sort(as.vector(unique(binned$TimeS))), 6)
head(orthogonal_polynomials)
ggplot(orthogonal_polynomials, aes(x=1, y=1)) +
geom_point() +
geom_point(aes(y=2), color='red') +
geom_point(aes(y=3), color='blue') +
geom_point(aes(y=4), color='green')
ggplot(data.frame(orthogonal_polynomials), aes(x=1, y=1)) +
geom_point() +
geom_point(aes(y=2), color='red') +
geom_point(aes(y=3), color='blue') +
geom_point(aes(y=4), color='green')
data.frame(orthogonal_polynomials)
ggplot(data.frame(orthogonal_polynomials), aes(x=X1, y=X1)) +
geom_point() +
geom_point(aes(y=X2), color='red') +
geom_point(aes(y=X3), color='blue') +
geom_point(aes(y=X4), color='green')
ggplot(data.frame(orthogonal_polynomials), aes(x=X1, y=X1)) +
geom_point() +
geom_point(aes(y=X2), color='red') +
geom_point(aes(y=X3), color='blue') +
geom_point(aes(y=X4), color='green') +
geom_point(aes(y=X5), color='purple') +
geom_point(aes(y=X6), color='yellow')
cor(orthogonal_polynomials[, c(1:6)])
round(cor(orthogonal_polynomials[, c(1:6)]),5)
time_codes <- data.frame(
sort(as.vector(unique(binned$TimeS))),
orthogonal_polynomials[, c(1:6)]
)
colnames(time_codes) <- c('TimeS','ot1','ot2','ot3','ot4','ot5','ot6')
binned <- merge(binned, time_codes, by='TimeS')
model <- lmer(elog ~ Target*(ot1 + ot2 + ot3) + (1 + Target + ot1 + ot2 + ot3 | ParticipantName), data = binned)
summary(model)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line")
summary(natural_model)
summary(model)
drop1(model, ~., test="Chisq")
model_quartic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3 + ot4) + (1 + TargetC + ot1 + ot2 + ot3 + ot4 | ParticipantName), data = binned)
summary(model_quartic)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed') + # 3rd-order model
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line") # 4th-order model
model <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3) + (1 + TargetC + ot1 + ot2 + ot3 | ParticipantName), data = binned)
anova(model, model_quartic)
model_cubic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3) + (1 + TargetC + ot1 + ot2 + ot3 + ot4 | ParticipantName), data = binned)
model_cubic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3) + (1 + TargetC + ot1 + ot2 + ot3 + ot4 | ParticipantName), data = binned, REML=F)
model_quartic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3 + ot4) + (1 + TargetC + ot1 + ot2 + ot3 + ot4 | ParticipantName), data = binned, REML=F)
anova(model_cubic, model_quartic)
model_quartic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3 + ot4) + (1 + TargetC + ot1 + ot2 + ot3 + ot4 + ot5 | ParticipantName), data = binned, REML=F)
model_quintic <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3 + ot4 + ot5) + (1 + TargetC + ot1 + ot2 + ot3 + ot4+ ot5  | ParticipantName), data = binned, REML=F)
anova(model_quartic, model_quintic)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed', color='black') + # 4th-order model
stat_summary(aes(y=predict(model_quintic,binned,re.form=NA)), fun.y=mean, geom="line") # 5th-order model
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed', color='black') + # 3rd-order model
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line") # 4th-order model
model <- lmer(elog ~ TargetC*(ot1 + ot2 + ot3) + (1 + TargetC + ot1 + ot2 + ot3 | ParticipantName), data = binned)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed', color='black') + # 3rd-order model
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line") # 4th-order model
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line") + # 3rd-order model
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line") # 4th-order model
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed') + # 3rd-order model
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line") # 4th-order model
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed') + # 4th-order model
stat_summary(aes(y=predict(model_quintic,binned,re.form=NA)), fun.y=mean, geom="line") # 5th-order model
model_linear <- lmer(elog ~ Target*(ot1) + (1 + Target + ot1 | ParticipantName), data = binned)
summary(model_linear)
model_linear <- lmer(elog ~ TargetC*(ot1) + (1 + TargetC + ot1 | ParticipantName), data = binned)
summary(model_linear)
ggplot(binned, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model_quartic,binned,re.form=NA)), fun.y=mean, geom="line", linetype='dashed') + # 3rd-order model
stat_summary(aes(y=predict(model_linear,binned,re.form=NA)), fun.y=mean, geom="line") # 2nd-order model
new_condition <- binned %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
new_condition <- binned %>%
filter(Target == 'Animal')
View(binned)
new_condition <- binned
new_condition <- binned %>%
filter(Target == 'Animal')
new_condition <- binned %>%
filter(Target == 'Animal')
new_condition <- data.frame(binned) %>%
filter(Target == 'Animal')
summary(binned)
binned[Target == 'Animal']
binned[which(Target == 'Animal'), ]
binned[which(binned$Target == 'Animal'), ]
new_condition <- binned %>%
filter(Target == 'Animal')
new_condition <- binned %>%
group_by(ParticipantName) %>%
summarise(MeanTest=mean(PropAnimal))
View(new_condition)
new_condition <- binned %>%
filter(Target == 'Animal')
colnames(binned)
new_condition <- binned %>%
filter(Target = 'Animal')
filter(binned, Target == 'Animal')
new_condition <- binned %>%
ungroup() %>%
filter(Target == 'Animal')
new_condition <- binned %>%
filter(TargetC == .5)
new_condition <- binned %>%
#filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
summary(binned)
detach("package:plyr",detach=T)
detach("package:plyr",unload=T)
binned <- data %>%
mutate(TimeS = TimeFromSubphaseOnset / 1000,
Bin = TimeFromSubphaseOnset %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) # arcsin-sqrt %>%
ungroup()
binned <- data %>%
mutate(TimeS = TimeFromSubphaseOnset / 1000,
Bin = TimeFromSubphaseOnset %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) %>% # arcsin-sqrt
ungroup()
binned$TargetC <- ifelse(binned$Target == 'Animal', .5, -.5)
binned$TargetC <- scale(binned$TargetC, center=T, scale=F)
model <- lmer(elog ~ TargetC*TimeS + (1 + TargetC + TimeS | ParticipantName), data = binned)
summary(model)
new_condition <- binned %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
new_condition <- binned %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
binned_3levels <- rbind(binned,new_condition)
binned_3levels$Target <- factor(binned_3levels$Target)
View(new_condition)
View(binned)
binned <- data %>%
mutate(TimeS = TimeFromSubphaseOnset / 1000,
Bin = TimeFromSubphaseOnset %/% 50) %>% # re-scale, bin
group_by(ParticipantName,Target,Bin) %>% # aggregate within bins
summarise(PropAnimal = mean(Animate), y = sum(Animate), N = length(Animate), TimeS = min(TimeS)) %>%
mutate(elog = log( (y + .5) / (N - y + .5) ), # empirical logit
wts = 1/(y + .5) + 1/(N - y + .5), # optional weights
Arcsin = asin(sqrt(PropAnimal))) %>% # arcsin-sqrt
ungroup()
binned$TargetC <- ifelse(binned$Target == 'Animal', .5, -.5)
binned$TargetC <- scale(binned$TargetC, center=T, scale=F)
binned <- binned %>%
mutate(TimeS_2 = TimeS^2,
TimeS_3 = TimeS^3,
TimeS_4 = TimeS^4)
orthogonal_polynomials <- poly(sort(as.vector(unique(binned$TimeS))), 6)
time_codes <- data.frame(
sort(as.vector(unique(binned$TimeS))),
orthogonal_polynomials[, c(1:6)]
)
colnames(time_codes) <- c('TimeS','ot1','ot2','ot3','ot4','ot5','ot6')
binned <- merge(binned, time_codes, by='TimeS')
new_condition <- binned %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
summary(binned)
data.frame(as.matrix(binned))
binned2 <- data.frame(as.matrix(binned))
View(binned2)
new_condition <- binned2 %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)),
y = ifelse(y > N, N, y),
y = ifelse(y < 1, 1, y),
PropAnimal = y / N,
elog = log(y / (N-y+.5)),
ArcSin = asin(sqrt(PropAnimal)))
View(new_condition)
new_condition <- binned2 %>%
filter(Target == 'Animal') %>%
mutate(Target = 'Neutral',
y = y + round(rnorm(length(y),0,2)))
summary(binned2)
binned2 <- as.matrix(binned)
new_condition <- binned2 %>%
filter(Target == 'Animal')
View(binned)
new_condition <- binned[which(binned$Target == 'Animal'), ]
new_condition$Target <- 'Neutral'
#new_condition$y <- new_condition$y - round(new_condition$N / 3)
new_condition$y <- new_condition$y + round(rnorm(length(new_condition$y),0,2))
new_condition$y <- ifelse(new_condition$y > new_condition$N,new_condition$N,new_condition$y)
new_condition[which(new_condition$y < 1), 'y'] <- 1
new_condition$PropAnimal <- new_condition$y / new_condition$N
new_condition$elog <- log( (new_condition$y) / (new_condition$N - new_condition$y + .5) )
new_condition$wts <- 1/(new_condition$y + .5) + 1/(new_condition$N - new_condition$y + .5)
new_condition$Arcsin <- asin(sqrt(new_condition$PropAnimal))
binned_3levels <- rbind(binned,new_condition)
binned_3levels$Target <- factor(binned_3levels$Target)
ggplot(binned_3levels, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point")
new_condition <- binned[which(binned$Target == 'Animal'), ]
new_condition$Target <- 'Neutral'
#new_condition$y <- new_condition$y - round(new_condition$N / 3)
new_condition$y <- new_condition$y + round(rnorm(length(new_condition$y),-.5,2))
new_condition$y <- ifelse(new_condition$y > new_condition$N,new_condition$N,new_condition$y)
new_condition[which(new_condition$y < 1), 'y'] <- 1
new_condition$PropAnimal <- new_condition$y / new_condition$N
new_condition$elog <- log( (new_condition$y) / (new_condition$N - new_condition$y + .5) )
new_condition$wts <- 1/(new_condition$y + .5) + 1/(new_condition$N - new_condition$y + .5)
new_condition$Arcsin <- asin(sqrt(new_condition$PropAnimal))
binned_3levels <- rbind(binned,new_condition)
binned_3levels$Target <- factor(binned_3levels$Target)
ggplot(binned_3levels, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point")
model <- lmer(elog ~ Target*(ot1 + ot2 + ot3) + (1 + Target + ot1 + ot2 + ot3 | ParticipantName), data = binned_3levels)
summary(model)
ggplot(binned_3levels, aes(x=TimeS, y=elog, color=Target)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(aes(y=predict(model,binned_3levels,re.form=NA)), fun.y=mean, geom="line")
summary(binned_3levels$Target)
levels(binned_3levels$Target)
binned_3levels$Target <- factor(binned_3levels$Target, levels=c('Neutral','Animal','Artefact'))
model <- lmer(elog ~ Target*(ot1 + ot2 + ot3) + (1 + Target + ot1 + ot2 + ot3 | ParticipantName), data = binned_3levels)
summary(model)
